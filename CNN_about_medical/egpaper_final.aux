\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{tajbakhsh2016convolutional}
\citation{ribeiro2016colonic}
\citation{zhang2017automatic}
\citation{mcilroy2017vivo}
\citation{li2017cell}
\citation{huang2017epithelium}
\citation{kieffer2017convolutional}
\citation{hadad2017classification}
\citation{araujo2017classification}
\citation{shen2015multi}
\citation{li2014medical}
\citation{prajapaticlassification}
\citation{roth2015anatomy}
\citation{zhang2017automatic}
\citation{ribeiro2016colonic}
\citation{ribeiro2016colonic}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Part III: CNN in medical image classification}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}introduction}{1}{subsection.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Accuracy results from different CNN configurations}}{1}{figure.1}}
\newlabel{fig:long}{{1}{1}{Accuracy results from different CNN configurations\relax }{figure.1}{}}
\newlabel{fig:onecol}{{1}{1}{Accuracy results from different CNN configurations\relax }{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\hskip -1em.\nobreakspace  {}Polyp detection}{1}{subsection.1.2}}
\citation{zhang2017automatic}
\citation{kieffer2017convolutional}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Accuracy of different strides for overlapping subimages in the evaluation.}}{2}{figure.2}}
\newlabel{fig:long}{{2}{2}{Accuracy of different strides for overlapping subimages in the evaluation}{figure.2}{}}
\newlabel{fig:onecol}{{2}{2}{Accuracy of different strides for overlapping subimages in the evaluation}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\hskip -1em.\nobreakspace  {}tissue detection and classification}{2}{subsection.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Average accuracy of the detection and classification tasks by transferring C1–Cn features learned from ILSVRC and Places205 and using SVM as the classifier with a RBF kernel.}}{2}{figure.3}}
\newlabel{fig:long}{{3}{2}{Average accuracy of the detection and classification tasks by transferring C1–Cn features learned from ILSVRC and Places205 and using SVM as the classifier with a RBF kernel}{figure.3}{}}
\newlabel{fig:onecol}{{3}{2}{Average accuracy of the detection and classification tasks by transferring C1–Cn features learned from ILSVRC and Places205 and using SVM as the classifier with a RBF kernel}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Typical ROC curve for polyp classification for PWH database.}}{2}{figure.4}}
\newlabel{fig:long}{{4}{2}{Typical ROC curve for polyp classification for PWH database}{figure.4}{}}
\newlabel{fig:onecol}{{4}{2}{Typical ROC curve for polyp classification for PWH database}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Average accuracy of the detection and classification tasks by transferring C1–Cn features learned from ILSVRC and using either RBF kernel SVM or a fully connected CNN layer with a softmax classifier}}{2}{figure.5}}
\newlabel{fig:long}{{5}{2}{Average accuracy of the detection and classification tasks by transferring C1–Cn features learned from ILSVRC and using either RBF kernel SVM or a fully connected CNN layer with a softmax classifier\relax }{figure.5}{}}
\newlabel{fig:onecol}{{5}{2}{Average accuracy of the detection and classification tasks by transferring C1–Cn features learned from ILSVRC and using either RBF kernel SVM or a fully connected CNN layer with a softmax classifier\relax }{figure.5}{}}
\citation{araujo2017classification}
\citation{shen2015multi}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparing the results training form scratch , using deep features via a pre-trained network with no change (FE-VGG16), and classification after fine-tuning a pre-trained network (TL-VGG16, TL-Inception-v3). The best scores are highlighted in bold.(\textit  {$\eta _p$} means the patch-to-scan accuracy and \textit  {$\eta _n$} means whole-scan accuracy)}}{3}{figure.6}}
\newlabel{fig:long}{{6}{3}{Comparing the results training form scratch , using deep features via a pre-trained network with no change (FE-VGG16), and classification after fine-tuning a pre-trained network (TL-VGG16, TL-Inception-v3). The best scores are highlighted in bold.(\textit {$\eta _p$} means the patch-to-scan accuracy and \textit {$\eta _n$} means whole-scan accuracy)\relax }{figure.6}{}}
\newlabel{fig:onecol}{{6}{3}{Comparing the results training form scratch , using deep features via a pre-trained network with no change (FE-VGG16), and classification after fine-tuning a pre-trained network (TL-VGG16, TL-Inception-v3). The best scores are highlighted in bold.(\textit {$\eta _p$} means the patch-to-scan accuracy and \textit {$\eta _n$} means whole-scan accuracy)\relax }{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Patch-wise sensitivity (\%) (2 and 4 classes).}}{3}{figure.7}}
\newlabel{fig:long}{{7}{3}{Patch-wise sensitivity (\%) (2 and 4 classes)}{figure.7}{}}
\newlabel{fig:onecol}{{7}{3}{Patch-wise sensitivity (\%) (2 and 4 classes)}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Image-wise accuracy (\%) using different voting rules (2 and 4 classes).}}{3}{figure.8}}
\newlabel{fig:long}{{8}{3}{Image-wise accuracy (\%) using different voting rules (2 and 4 classes)}{figure.8}{}}
\newlabel{fig:onecol}{{8}{3}{Image-wise accuracy (\%) using different voting rules (2 and 4 classes)}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Image-wise sensitivity (\%) using majority voting (2 and 4 classes).}}{3}{figure.9}}
\newlabel{fig:long}{{9}{3}{Image-wise sensitivity (\%) using majority voting (2 and 4 classes)}{figure.9}{}}
\newlabel{fig:onecol}{{9}{3}{Image-wise sensitivity (\%) using majority voting (2 and 4 classes)}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}\hskip -1em.\nobreakspace  {}Some kinds of lung diseases classification}{3}{subsection.1.4}}
\citation{shen2015multi}
\citation{li2014medical}
\citation{prajapaticlassification}
\citation{roth2015anatomy}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The classification performance of SVM with the RBF kernel and RF based on features from the MCNN using 8 different configurations. Each configuration is assigned to a unique ID for display convenience}}{4}{figure.10}}
\newlabel{fig:long}{{10}{4}{The classification performance of SVM with the RBF kernel and RF based on features from the MCNN using 8 different configurations. Each configuration is assigned to a unique ID for display convenience\relax }{figure.10}{}}
\newlabel{fig:onecol}{{10}{4}{The classification performance of SVM with the RBF kernel and RF based on features from the MCNN using 8 different configurations. Each configuration is assigned to a unique ID for display convenience\relax }{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Performance using the HOG and LBP descriptors with different \textit  {$S_w$} and \textit  {$n_{pt}$}}}{4}{figure.11}}
\newlabel{fig:long}{{11}{4}{Performance using the HOG and LBP descriptors with different \textit {$S_w$} and \textit {$n_{pt}$}\relax }{figure.11}{}}
\newlabel{fig:onecol}{{11}{4}{Performance using the HOG and LBP descriptors with different \textit {$S_w$} and \textit {$n_{pt}$}\relax }{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The classification results comparing proposed customized CNN method with SIFT, LBP and RBM}}{4}{figure.12}}
\newlabel{fig:long}{{12}{4}{The classification results comparing proposed customized CNN method with SIFT, LBP and RBM\relax }{figure.12}{}}
\newlabel{fig:onecol}{{12}{4}{The classification results comparing proposed customized CNN method with SIFT, LBP and RBM\relax }{figure.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}\hskip -1em.\nobreakspace  {}dental disease classification in X-ray images}{4}{subsection.1.5}}
\bibstyle{ieee}
\bibdata{egbib}
\bibcite{araujo2017classification}{1}
\bibcite{hadad2017classification}{2}
\bibcite{huang2017epithelium}{3}
\bibcite{kieffer2017convolutional}{4}
\bibcite{li2014medical}{5}
\bibcite{li2017cell}{6}
\bibcite{mcilroy2017vivo}{7}
\bibcite{prajapaticlassification}{8}
\bibcite{ribeiro2016colonic}{9}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The comparison of different models}}{5}{figure.13}}
\newlabel{fig:long}{{13}{5}{The comparison of different models\relax }{figure.13}{}}
\newlabel{fig:onecol}{{13}{5}{The comparison of different models\relax }{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Experimental results for transfer learning model}}{5}{figure.14}}
\newlabel{fig:long}{{14}{5}{Experimental results for transfer learning model\relax }{figure.14}{}}
\newlabel{fig:onecol}{{14}{5}{Experimental results for transfer learning model\relax }{figure.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}\hskip -1em.\nobreakspace  {}intima-media boundary segmentation}{5}{subsection.1.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}\hskip -1em.\nobreakspace  {}Conclusion}{5}{subsection.1.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Confusion matrices on the original test images before and after data augmentation.}}{5}{figure.15}}
\newlabel{fig:long}{{15}{5}{Confusion matrices on the original test images before and after data augmentation}{figure.15}{}}
\newlabel{fig:onecol}{{15}{5}{Confusion matrices on the original test images before and after data augmentation}{figure.15}{}}
\bibcite{roth2015anatomy}{10}
\bibcite{shen2015multi}{11}
\bibcite{tajbakhsh2016convolutional}{12}
\bibcite{zhang2017automatic}{13}
